Framing: Key ML Terminology
https://developers.google.com/machine-learning/crash-course

--? What is supervised machine learning?
Given data input (training set), the Machine Learning System (MLS) utilizes the data input to analyze the unknown data.
In other words, having learning about many settings of characteristics of an entity, given a new incomplete setting of characteristics of the entity, what can we say about the other missing characteristics of the entity.

--? What is a label?
A label is the thing that we try to predict its value. The label could be considered as one of the characteristics that the entity has.

--? What is a feature?
A feature is one of the characteristics of the entity that we are studying. For example, for spam detector, the entity is email, and the features are words in the email text, sender's address, time of the day the email was sent.

--? What is an example?
An example is one instance of the data. We can say that it's one of the settings of the characteristics of the entity.
There are two types of example, one is labeled examples and the other is unlabeld examples. The labeled example includes all the characteristics of the entity. The unlabeled example includes all characteristics of the entity, but the one that we try to infer about. We use labeled example as a thorough understanding of the entity, to learn about the entity, to use it as a fact about the entity. Using the labeled examples, we can build a model that can infer about the missing label on the unlabeled examples. Note that example can contain false values which introduces noice and contaminates our model.

--? What is a model?
A model defines the relationship between features and label; in other words, relationship between one characteristic to other characteristics of an entity. i.e. a spam detection model might associate certain features strongly with "spam".
For each model, there are two phases of its life:
	Training means creating or learning the model. Expose the model to labeled examples so that the model can learn the relationship between one characteristic and the other characteristics of the entity.
	Inference means applying the trained model to unlabeled examples. Let the model predict the value of the characteristic when what it know only is the other characteristics of the entity. i.e. during inference, the model can predict medianHouseValue for new unlabeled examples.

--? What is the difference between regression vs. classification models?
A regression model predicts continuous values, meaning real values. i.e. What is the value of a house in California? or What is the probability that a user will click on this ad?
A classification model predicts discrete values, meaning finite set of values. i.e. Is a given email message spam or not spam? or Is this an image of a dog, a cat, or a hamster?

--? An example of linear regression.
We want to investigate the relationship between cricket's chirps per minute and the temperature in Celcius. We attempt to draw a line to capture the relationship between these two characteristics. Mathematically, we can numerically capture this relationship with this equation y = mx + b, where y is the temperature(what we want to predict), m is the slope of the line, x is the number of chirps per minute(what we use to predict), and b is the y-intercept. Converting this equation from mathematics context to machine learning context, we use a little bit different naming convention for the variables. The equation would be rewritten as y' = b + w1.x1, where y' is the predicted label, b is the bias(y-intercept), w1 is the weight of feature 1(slop of the line), and x1 is the feature.
To infer the temperature y' for a new chirps-per-minute value x1 in our example, substitute the value and calculate the equation to get the value for y'.
For a more sophisticated model, it may use multiple characteristics to predict the label. i.e The equation would be y' = b + w1.x1 + w2.x2 + w3.x3

--? What does it means when we say we are traing a model?
Training a model simply means learning (determining, figuring out) the good values for all the weights and the bias from labeled examples. In other words, we need to draw the relationship line, which requires figuring the best values for the slop and the intercept. How would we be able to determine the optimal values for the bias and the intercept? We need to use the labeled examples to estimate the values for the weights and the bias. In supervised learning, we build a model by examining many examples and attempting to find a model that minimizes loss; this is called empirical risk minimization.

--? What is loss?
Loss is the penalty for a bad prediction. Loss is the number indicating how bad the model's prediction was on a single example. If the model's prediction is prefect, the loss would be zero; otherwise, the loss is greater. The goal of training a model is to discover a set of weights and bias such that the model has low loss, on average, across all labeled examples.
Basically, loss is the difference between the line(model) and the examples.

--? How do we measure aggregate loss(differences between the model and the examples)?
We can use squared loss(a popular loss function) L2 loss. The squared loss for a single example is as follows
i.e. for a single example, we calculate the loss as follow.
squared loss L2 = the square of the difference between the label and the prediction
= (observations - prediction(x))^2 = (y- y')^2
Mean square error (MSE) is the average squared loss per example over the whole dataset. Sum up all the squared loss for all the examples, then divide by the number of examples.
MSE = SUM[all examples](y-y')^2

--? How can a model reduces the loss iteratively?
How do we modify our model to obtain a possibly better model? Given that we've created some model, tuning the model to devise a better model is always what we want to aim for. There are so many ways to tune the model, so the real trick is how we can efficiently search for the best model if possible. Key point: A machine learning model is trained by starting with guess values for the weights and bias, then iteratively modifies thoses guesses until learning the weights and bias with the lowest possible loss. Once the overall loss stops changing or at least changes are extremely slow, then we say the model has converged.

features --- model with parameters such as weights and bias -----> predict y' \
						^														v
						|Adjust parameters <------compute the loss L2 = sum all (y - y')^2
																				^
label    --------------------------------------------------------> actual  y  / 

--? How do we efficiently find the convergence point, which is the optimal value of the weight such that the loss is minimum?
Given a example (x, y) and y' = w0 + w1.x, we have L2 = (y - y') ^2 = (y - w1.x)^2 = (b - w1.a) ^2 where the value of a and b are already known, so L2 is a function of w1. Thus, we can plot the loss curve.
We can use the inefficient way, the brute force way, to calculate the loss for each of the possible values of the weight. A more efficient and popular method to find the optimal value for the weight is using gradient descent. The overall process is as follow: First, we'll pick a random value for the weight, then calculate gradient of the loss curve at that point w1 to know the direction and the magnitude of change since gradient is a vector. The gradient always points in the direction of steepest INCREASE in the loss function. The gradient descent algorithm goes the opposite direction to reduce loss as quickly as possible. Since we know the direction and the magnitude in which we can minimize the loss, we update our weight by a fraction of the gradient magnitude to further ourselves to the minimum point.

?-- What is a gradient of a function?
The gradient of a function %f is the vector of partial derivatives with respect to all of the independent variables %f
ie. if f(x, y) = e^(2y).sin(x)
then %f = (df(x, y)/dx, df(x, y)/dy) = (e^(2y).cos(x), 2e^(2y).sin(x))
note that %f points in the direction of greatest increase of the function, so -%f points in the direction of greatest decrease of the function. Where %f is a vector (a vector has the head and tail point, usually the tail is at the orgin of the coordinate system.

?-- What is learning rate?
Learning rate is a scalar that is used to control the velocity of applying gradient descent on discovering the minimum or the valley. As the gradient is a vector with magnitude and direction, instead of simply updating the weight using the magnitude, we can adjust the magnitude by multiplying it with the learning rate. If the learning rate is less than 1, we reduce the magnitude of the original gradient, and if the learning rate is greater than 1, we increase the magnitude of the original gradient. i.e if the gradient magnitude is 2.5 and the learning rate is 0.01, then the gradient descent algorithm will pick the next point 0.025 away from the previous point.

?-- What are hyperparameters?
Hyperparameters are knobs that programmers tweak in machine learning algorithms. In our example, the knob is the learning rate. If we tune the learning rate to a small number, then it may take forever to reach the minimum valley. If we tune the learning rate to a large number, it may bounce back and forth before it finally reaches the valley. The ideal learning rate in one-dimension is 1/f(x)^n (the inverse of the second derivative of f(x) at x)

?-- What are precaution when trying to set the learning rate?
Setting the learning rate too large would make the gradient descent never reaches the minimum, so the key point is finding a learning rate that is large enough such that the gradient descent converges efficiently.

?-- What is a batch in gradient descent?
A batch is the total number of examples we use to calculate the gradient in a single iteration. ie, we take 1 example, and create the loss function. With the values of x and y known, the loss function becomes the function of the weight w1, from which we can draw a graph of w1 and loss. Pick a random value for w1, we calculate the gradient for this example. Then we take another example, do the same thing, draw the graph of weight and loss, and use the same value for weight from the first example to calculate the gradient. Then we take the average of these gradients.

?-- What is stochastic gradient descent(SGD)?
Stochastic gradient descent is an extreme take on gradient descent, in which it uses only a single example(a batch size of 1) per iteration. SGD works but very noisy. Specifically, the one example in the batch is chosen at random.

?-- What is mini-batch stochastic gradient descent(mini-batch SGD)?
It is the intermediate between full-batch iteration and SGD. A mini-batch is typically between 10 and 1,000 examples, chosen at random. Mini-batch SGD reduces the amount of noise in SGD but is still more efficient than full-batch.

?-- What are the risks of overfiting?
Sometimes the model overfits the training data. An overfit model gets a low loss during training but does a poor job predicting new data. The fundamental tension of machine learning is between fitting our data well, but also fitting the data as simply as possible.
Machine learning's goal is to predict accurately on new data drawn from a hidding true probability distribution. Not how well you train the model, but how well the model can predict the label given the new data. 
The fields statistical learning theory and computational learning theory have developed generalization bounds - a statistical description of a model's ability to generalize to new data based on factors such as the complexity of the model and the model's performance on training data. The theoretical analysis provides formal guarantees under idealized assumptions, thus being difficult to apply in practice.

?-- How would we get the previously unseen data?
We divide the data set into two subsets such as training set(a subset to train a model) and test set(a subset to test the model). After we train our model using the training set, we can test our model with the test set to see how well our model generalize. Assuming the test set is large enough(split 30% training set and 70% test set?)

?-- What are the basic assumptions that guide generalization?
We need to draw examples independently and identically(i.i.d) at random from the distribution. In other words, examples don't influence each other. An example of violation of this assumption is the model bases its choice of ads on what ads the user has previously seen.
The distribution is stationary. In other words, the distribution doesn't change within the data set. An example of violation of stationarity principle is that given the data set that contains retail sales information for a year, user's purchases change seasonally, meaning that the sales concentrate in some months such as December with Thanksgiving or Christmas, and other months the sales are less likely or even worse when compared with December.
Draw examples from partitions from the same distribution.

--? What are considerations when we divide the examples to training set and test set?
Make sure that your test set meets the following two conditions: large enough to yield statistically meaningful results, and representative of data set as a whole. In other words, test set must have the same characteristics like the training set.
Our test set serves as a proxy for new data.

--? Oh I've seen surprisingly good results on my evaluation metrics, does it mean that i'm solid and good to go?
No, that might be a sign that we are accidentally training on the test set. For example, high accuracy might indicate that test data has leaked into the training set. For example, building a model that predicts whether an email is spam using subject line, email body, sender's email address as features. We split data into 80-20, then training the model. After that we evaluate the model with the test set, and we achive 99% precision. What a great job we did! No, looking carefully at the data, we see that examples in the test set are duplicates of examples in the training set. That's why we achive so high precision on the test set. That is one of the cautions that we need to pay attention to before splitting data into training set and test set. In this case, we can try to eliminate duplicates on the data set before we split the data. Unless we eliminate duplicate examples, we are no longer accurately measuring how well our model generalizes to new data. When we test our model with the test set, we evaluate the model's generalization ability.

--? What is the problem of using only training set and test set with iteration to tune the hyperparameters?
Let's look at our machine learning workflow

training model on the Training set ----------> evaluate model on test set
the tweak model according to results on Test set to obtain a better score on the next iterative test with the same test set. Finally, pick the model that does best on Test Set.
Tweak model means adjusting anything about the model you can dream up - from changing the learning rate, to adding or removing features, to designing a completely new model from scratch. At the end of this workflow, pick the model that does best on the test set. Because the best model is tuned based on the test set, adjusting hyperparameters is influenced by the test set, making the model fit to the test data. Another better approach would be partition the examples into three subsets, which are training set, validation set, and test set. So the workflow has changed to the following: first, pick the model that does best on the validation set, then double-check that model against the test set.
The test sets and validation sets wear out with repeated use, meaning that we should not try to optimize the results on the test sets and validation sets by performing so many iterations.